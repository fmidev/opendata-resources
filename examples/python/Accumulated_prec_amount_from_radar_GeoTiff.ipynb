{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate precipitation sum from GeoTiff radar images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnish Meteorological Institute is providing radar images as GeoTiff in S3 bucket. The data is free and openly available with CC4BY license.\n",
    "\n",
    "This is a short and simple example how to calculate accumulated precipitation amount from GeoTiff radar images of precipitation rate (rr) with 5 minute interval. The example is ment to illustrate how to use the data with python.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we install necessary libraries. Rasterio (https://github.com/mapbox/rasterio) is used to fetch the data and pyproj (https://pypi.org/project/pyproj/) to calculate coordinate transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio[s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from datetime import datetime, timedelta\n",
    "from pyproj import Proj, Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small helper function to handle time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundTime(dt, roundTo=300):\n",
    "   \"\"\"\n",
    "   Round a datetime object to any time lapse in seconds\n",
    "   \n",
    "   dt      : datetime.datetime object\n",
    "             DateTime to round\n",
    "   roundTo : int\n",
    "             Closest number of seconds to round to, default 1 minute. \n",
    "   \n",
    "   Returns\n",
    "   -------\n",
    "   datetime.datetime object\n",
    "            Modified datetime   \n",
    "   \"\"\"\n",
    "   seconds = (dt.replace(tzinfo=None) - dt.min).seconds\n",
    "   rounding = (seconds+roundTo/2) // roundTo * roundTo\n",
    "   return dt + timedelta(0,rounding-seconds,-dt.microsecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function opens the geotiff image from S3 bucket and sample pixel value from requested coordinates. Note that images are in EPSG:3067 projection so we need to reproject the coordinates. \n",
    "\n",
    "Finally, pixel values are converted to millimeters. Conversions are documented here: https://en.ilmatieteenlaitos.fi/open-data-manual-radar-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_timestep(bucket, key, x, y, mode='rr', timestep=300):\n",
    "    \"\"\" Process time step\n",
    "    \n",
    "    bucket   : str \n",
    "               S3 bucket name (where radar images exist)\n",
    "    key      : str\n",
    "               Radar image key in the bucket\n",
    "    lat      : float\n",
    "               Latitude of the point of interest\n",
    "    lon      : float\n",
    "               Longitude of the point of interest    \n",
    "    mode     : str\n",
    "               Defines how pixel values are converted to millimeters\n",
    "    timestep : int\n",
    "               Time step of radar images (used in pixel --> mm conversion)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float \n",
    "         Precipitation amount in millimeters\n",
    "    \"\"\"    \n",
    "    with rio.open('s3://{}/{}'.format(bucket, key)) as src:\n",
    "        for val in src.sample([(x, y)]):\n",
    "            if mode == 'rr':\n",
    "                return val[0]*.01*timestep/3600\n",
    "            else:\n",
    "                raise Exception('mode not implemented')\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we define a function to go through requested time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_range(bucket, starttime, endtime, lat, lon, timestep, mode = 'rr', filename_start='geotiff/', filename_end='_SUOMI500-rr.tif'):\n",
    "    \"\"\" Process time range \n",
    "    bucket    : str \n",
    "                S3 bucket name (where radar images exist)\n",
    "    starttime : str\n",
    "                Start time of the time range in format %Y-%m-%d %H:%M:%S\n",
    "    endtime   : str\n",
    "                End time of the time range in format %Y-%m-%d %H:%M:%S                \n",
    "    lat       : float\n",
    "                Latitude of the point of interest\n",
    "    lon       : float\n",
    "                Longitude of the point of interest    \n",
    "    timestep  : int\n",
    "                Time step of radar images\n",
    "    mode      : str\n",
    "                Defines how pixel values are converted to millimeters\n",
    "    filename_start : str\n",
    "                     For example path of the image. Images are assumed to found with name \n",
    "                     filename_start+timestamp+filename_end.  \n",
    "    filename_start : str\n",
    "                 Images are assumed to found with name filename_start+timestamp+filename_end.  \n",
    "                      \n",
    "    Returns\n",
    "    -------\n",
    "    float \n",
    "         Precipitation amount in millimeters\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    start = roundTime(datetime.strptime(starttime, '%Y-%m-%d %H:%M:%S'))\n",
    "    end = roundTime(datetime.strptime(endtime, '%Y-%m-%d %H:%M:%S'))    \n",
    "    time_it = start    \n",
    "    \n",
    "    transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3067\")\n",
    "    x,y = transformer.transform(lat, lon)\n",
    "    \n",
    "    prec_sum = 0\n",
    "    while time_it <= end:\n",
    "        key = '{}{}{}'.format(filename_start, time_it.strftime('%Y%m%d%H%M'), filename_end)\n",
    "        prec_sum += process_timestep(bucket, key, x, y, timestep=timestep)\n",
    "\n",
    "        if time_it.minute == 0: print('{:.2f}'.format(prec_sum), end='')\n",
    "        else: print('.', end='')\n",
    "            \n",
    "        time_it +=  timedelta(seconds=timestep)\n",
    "\n",
    "    print('')\n",
    "    return prec_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we run everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'fmi-radar-opendata-sandbox'\n",
    "starttime = '2020-07-11 00:00:00'\n",
    "endtime = '2020-07-11 23:59:00'\n",
    "lat = 63.1593\n",
    "lon = 29.8346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00...........0.00...........0.00...........0.00...........0.00...........0.00...........0.00...........0.00...........0.00...........0.00...........0.00...........0.02...........0.61...........3.26...........9.86...........11.49...........12.91...........17.49...........19.29...........19.86...........20.08...........20.08...........20.08...........20.08...........20.08\n",
      "Precipitation sum at 63.1593,29.8346 (Koli, Finland) on 11th July 2020 is 20.08 mm\n"
     ]
    }
   ],
   "source": [
    "prec_sum = process_time_range(bucket, starttime, endtime, lat, lon, 300)\n",
    "print('Precipitation sum at {},{} (Koli, Finland) on 11th July 2020 is {:.2f} mm'.format(lat,lon,prec_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask version\n",
    "\n",
    "As the above computation contains almost 300 geotiff images to process, it does take some time. If we want to calculate precipitation sum over longer period or do some other heavy computation, it may be good idea to distritbute the calculation. Following example shows how this can achieved using Dask (https://docs.dask.org/en/latest/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to install the envinronment. This example does not cover installing dask but all assets used to setup the dask cluster are included in the repository. A good tutorial for setting up the cluster can be found at: https://towardsdatascience.com/serverless-distributed-data-pre-processing-using-dask-amazon-ecs-and-python-part-1-a6108c728cc4\n",
    "\n",
    "To use the cluster, we need several libraries to be installed. Following commands install the require libraries. Versions of each libraries are defined as they need to mach with the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y enum34\n",
    "!pip install blosc==1.8.3\n",
    "!pip install --upgrade joblib==0.15.1 dask[dataframe]==2.12.0 distributed==2.12.0 lz4==3.0.2 cloudpickle==1.3.0 msgpack==1.0.0 numpy==1.18.1 toolz==0.10.0 tornado==6.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import necessary libraries and initialize dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('Dask-Scheduler.local-dask:8786')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define necessary variables. These are the same as in previous example except that we have a longer time range and we use start and end times as DateTime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'fmi-radar-opendata-sandbox'\n",
    "lat = 63.1593\n",
    "lon = 29.8346\n",
    "timestep=300\n",
    "filename_start='geotiff/'\n",
    "filename_end='_SUOMI500-rr.tif'\n",
    "starttime = datetime.strptime('2020-07-11 00:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "endtime = datetime.strptime('2020-07-15 23:59:00', \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing is also almost similar to local version. We go through the time steps but instead of directly calculating the value, we define the calculation and call dask to compute all at once. Dask handles the distribution and gathering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitation sum at 63.1593,29.8346 (Koli, Finland) on between 11th Jul 2020 - 15th Jul 2020 is 28.77 mm\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3067\")\n",
    "x,y = transformer.transform(lat, lon)\n",
    "\n",
    "dfs, df = [], []\n",
    "time_it = starttime\n",
    "while time_it <= endtime:\n",
    "    key = '{}{}{}'.format(filename_start, time_it.strftime('%Y%m%d%H%M'), filename_end)\n",
    "    dfs.append(delayed(process_timestep)(bucket, key, x, y, timestep=timestep))\n",
    "    time_it +=  timedelta(seconds=timestep)\n",
    "\n",
    "df = dask.compute(*dfs)\n",
    "\n",
    "print('Precipitation sum at {},{} (Koli, Finland) on between {} - {} is {:.2f} mm'.format(lat,\n",
    "                                                                                          lon,\n",
    "                                                                                          starttime.strftime('%dth %b %Y'), \n",
    "                                                                                          endtime.strftime('%dth %b %Y'), \n",
    "                                                                                          sum(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
